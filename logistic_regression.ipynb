{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the csv file, del 2 columns from the file, checking first few rows of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  EstimatedSalary  Purchased\n",
       "0   19            19000          0\n",
       "1   35            20000          0\n",
       "2   26            43000          0\n",
       "3   27            57000          0\n",
       "4   19            76000          0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('data/Social_Network_Ads.csv')\n",
    "dataset.drop(columns=['User ID','Gender',],axis=1,inplace=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declare label as last column in the source file\n",
    "y = dataset.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaring X as all columns excluding last\n",
    "X = dataset.iloc[:,:-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_train, A_test, b_train, b_test = train_test_split(X,y,test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sacaling data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "A_train = sc.fit_transform(A_train)\n",
    "A_test = sc.transform(A_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.58164944, -0.88670699],\n",
       "       [-0.60673761,  1.46173768],\n",
       "       [-0.01254409, -0.5677824 ],\n",
       "       [-0.60673761,  1.89663484],\n",
       "       [ 1.37390747, -1.40858358],\n",
       "       [ 1.47293972,  0.99784738],\n",
       "       [ 0.08648817, -0.79972756],\n",
       "       [-0.01254409, -0.24885782],\n",
       "       [-0.21060859, -0.5677824 ],\n",
       "       [-0.21060859, -0.19087153],\n",
       "       [-0.30964085, -1.29261101],\n",
       "       [-0.30964085, -0.5677824 ],\n",
       "       [ 0.38358493,  0.09905991],\n",
       "       [ 0.8787462 , -0.59677555],\n",
       "       [ 2.06713324, -1.17663843],\n",
       "       [ 1.07681071, -0.13288524],\n",
       "       [ 0.68068169,  1.78066227],\n",
       "       [-0.70576986,  0.56295021],\n",
       "       [ 0.77971394,  0.35999821],\n",
       "       [ 0.8787462 , -0.53878926],\n",
       "       [-1.20093113, -1.58254245],\n",
       "       [ 2.1661655 ,  0.93986109],\n",
       "       [-0.01254409,  1.22979253],\n",
       "       [ 0.18552042,  1.08482681],\n",
       "       [ 0.38358493, -0.48080297],\n",
       "       [-0.30964085, -0.30684411],\n",
       "       [ 0.97777845, -0.8287207 ],\n",
       "       [ 0.97777845,  1.8676417 ],\n",
       "       [-0.01254409,  1.25878567],\n",
       "       [-0.90383437,  2.27354572],\n",
       "       [-1.20093113, -1.58254245],\n",
       "       [ 2.1661655 , -0.79972756],\n",
       "       [-1.39899564, -1.46656987],\n",
       "       [ 0.38358493,  2.30253886],\n",
       "       [ 0.77971394,  0.76590222],\n",
       "       [-1.00286662, -0.30684411],\n",
       "       [ 0.08648817,  0.76590222],\n",
       "       [-1.00286662,  0.56295021],\n",
       "       [ 0.28455268,  0.07006676],\n",
       "       [ 0.68068169, -1.26361786],\n",
       "       [-0.50770535, -0.01691267],\n",
       "       [-1.79512465,  0.35999821],\n",
       "       [-0.70576986,  0.12805305],\n",
       "       [ 0.38358493,  0.30201192],\n",
       "       [-0.30964085,  0.07006676],\n",
       "       [-0.50770535,  2.30253886],\n",
       "       [ 0.18552042,  0.04107362],\n",
       "       [ 1.27487521,  2.21555943],\n",
       "       [ 0.77971394,  0.27301877],\n",
       "       [-0.30964085,  0.1570462 ],\n",
       "       [-0.01254409, -0.53878926],\n",
       "       [-0.21060859,  0.1570462 ],\n",
       "       [-0.11157634,  0.24402563],\n",
       "       [-0.01254409, -0.24885782],\n",
       "       [ 2.1661655 ,  1.11381995],\n",
       "       [-1.79512465,  0.35999821],\n",
       "       [ 1.86906873,  0.12805305],\n",
       "       [ 0.38358493, -0.13288524],\n",
       "       [-1.20093113,  0.30201192],\n",
       "       [ 0.77971394,  1.37475825],\n",
       "       [-0.30964085, -0.24885782],\n",
       "       [-1.6960924 , -0.04590581],\n",
       "       [-1.00286662, -0.74174127],\n",
       "       [ 0.28455268,  0.50496393],\n",
       "       [-0.11157634, -1.06066585],\n",
       "       [-1.10189888,  0.59194336],\n",
       "       [ 0.08648817, -0.79972756],\n",
       "       [-1.00286662,  1.54871711],\n",
       "       [-0.70576986,  1.40375139],\n",
       "       [-1.29996338,  0.50496393],\n",
       "       [-0.30964085,  0.04107362],\n",
       "       [-0.11157634,  0.01208048],\n",
       "       [-0.30964085, -0.88670699],\n",
       "       [ 0.8787462 , -1.3505973 ],\n",
       "       [-0.30964085,  2.24455257],\n",
       "       [ 0.97777845,  1.98361427],\n",
       "       [-1.20093113,  0.47597078],\n",
       "       [-1.29996338,  0.27301877],\n",
       "       [ 1.37390747,  1.98361427],\n",
       "       [ 1.27487521, -1.3505973 ],\n",
       "       [-0.30964085, -0.27785096],\n",
       "       [-0.50770535,  1.25878567],\n",
       "       [-0.80480212,  1.08482681],\n",
       "       [ 0.97777845, -1.06066585],\n",
       "       [ 0.28455268,  0.30201192],\n",
       "       [ 0.97777845,  0.76590222],\n",
       "       [-0.70576986, -1.49556302],\n",
       "       [-0.70576986,  0.04107362],\n",
       "       [ 0.48261718,  1.72267598],\n",
       "       [ 2.06713324,  0.18603934],\n",
       "       [-1.99318916, -0.74174127],\n",
       "       [-0.21060859,  1.40375139],\n",
       "       [ 0.38358493,  0.59194336],\n",
       "       [ 0.8787462 , -1.14764529],\n",
       "       [-1.20093113, -0.77073441],\n",
       "       [ 0.18552042,  0.24402563],\n",
       "       [ 0.77971394, -0.30684411],\n",
       "       [ 2.06713324, -0.79972756],\n",
       "       [ 0.77971394,  0.12805305],\n",
       "       [-0.30964085,  0.6209365 ],\n",
       "       [-1.00286662, -0.30684411],\n",
       "       [ 0.18552042, -0.3648304 ],\n",
       "       [ 2.06713324,  2.12857999],\n",
       "       [ 1.86906873, -1.26361786],\n",
       "       [ 1.37390747, -0.91570013],\n",
       "       [ 0.8787462 ,  1.25878567],\n",
       "       [ 1.47293972,  2.12857999],\n",
       "       [-0.30964085, -1.23462472],\n",
       "       [ 1.96810099,  0.91086794],\n",
       "       [ 0.68068169, -0.71274813],\n",
       "       [-1.49802789,  0.35999821],\n",
       "       [ 0.77971394, -1.3505973 ],\n",
       "       [ 0.38358493, -0.13288524],\n",
       "       [-1.00286662,  0.41798449],\n",
       "       [-0.01254409, -0.30684411],\n",
       "       [-1.20093113,  0.41798449],\n",
       "       [-0.90383437, -1.20563157],\n",
       "       [-0.11157634,  0.04107362],\n",
       "       [-1.59706014, -0.42281668],\n",
       "       [ 0.97777845, -1.00267957],\n",
       "       [ 1.07681071, -1.20563157],\n",
       "       [-0.01254409, -0.13288524],\n",
       "       [-1.10189888, -1.52455616],\n",
       "       [ 0.77971394, -1.20563157],\n",
       "       [ 0.97777845,  2.07059371],\n",
       "       [-1.20093113, -1.52455616],\n",
       "       [-0.30964085,  0.79489537],\n",
       "       [ 0.08648817, -0.30684411],\n",
       "       [-1.39899564, -1.23462472],\n",
       "       [-0.60673761, -1.49556302],\n",
       "       [ 0.77971394,  0.53395707],\n",
       "       [-0.30964085, -0.33583725],\n",
       "       [ 1.77003648, -0.27785096],\n",
       "       [ 0.8787462 , -1.03167271],\n",
       "       [ 0.18552042,  0.07006676],\n",
       "       [-0.60673761,  0.8818748 ],\n",
       "       [-1.89415691, -1.40858358],\n",
       "       [-1.29996338,  0.59194336],\n",
       "       [-0.30964085,  0.53395707],\n",
       "       [-1.00286662, -1.089659  ],\n",
       "       [ 1.17584296, -1.43757673],\n",
       "       [ 0.18552042, -0.30684411],\n",
       "       [ 1.17584296, -0.74174127],\n",
       "       [-0.30964085,  0.07006676],\n",
       "       [ 0.18552042,  2.09958685],\n",
       "       [ 0.77971394, -1.089659  ],\n",
       "       [ 0.08648817,  0.04107362],\n",
       "       [-1.79512465,  0.12805305],\n",
       "       [-0.90383437,  0.1570462 ],\n",
       "       [-0.70576986,  0.18603934],\n",
       "       [ 0.8787462 , -1.29261101],\n",
       "       [ 0.18552042, -0.24885782],\n",
       "       [-0.4086731 ,  1.22979253],\n",
       "       [-0.01254409,  0.30201192],\n",
       "       [ 0.38358493,  0.1570462 ],\n",
       "       [ 0.8787462 , -0.65476184],\n",
       "       [ 0.08648817,  0.1570462 ],\n",
       "       [-1.89415691, -1.29261101],\n",
       "       [-0.11157634,  0.30201192],\n",
       "       [-0.21060859, -0.27785096],\n",
       "       [ 0.28455268, -0.50979612],\n",
       "       [-0.21060859,  1.6067034 ],\n",
       "       [ 0.97777845, -1.17663843],\n",
       "       [-0.21060859,  1.63569655],\n",
       "       [ 1.27487521,  1.8676417 ],\n",
       "       [-1.10189888, -0.3648304 ],\n",
       "       [-0.01254409,  0.04107362],\n",
       "       [ 0.08648817, -0.24885782],\n",
       "       [-1.59706014, -1.23462472],\n",
       "       [-0.50770535, -0.27785096],\n",
       "       [ 0.97777845,  0.12805305],\n",
       "       [ 1.96810099, -1.3505973 ],\n",
       "       [ 1.47293972,  0.07006676],\n",
       "       [-0.60673761,  1.37475825],\n",
       "       [ 1.57197197,  0.01208048],\n",
       "       [-0.80480212,  0.30201192],\n",
       "       [ 1.96810099,  0.73690908],\n",
       "       [-1.20093113, -0.50979612],\n",
       "       [ 0.68068169,  0.27301877],\n",
       "       [-1.39899564, -0.42281668],\n",
       "       [ 0.18552042,  0.1570462 ],\n",
       "       [-0.50770535, -1.20563157],\n",
       "       [ 0.58164944,  2.01260742],\n",
       "       [-1.59706014, -1.49556302],\n",
       "       [-0.50770535, -0.53878926],\n",
       "       [ 0.48261718,  1.83864855],\n",
       "       [-1.39899564, -1.089659  ],\n",
       "       [ 0.77971394, -1.37959044],\n",
       "       [-0.30964085, -0.42281668],\n",
       "       [ 1.57197197,  0.99784738],\n",
       "       [ 0.97777845,  1.43274454],\n",
       "       [-0.30964085, -0.48080297],\n",
       "       [-0.11157634,  2.15757314],\n",
       "       [-1.49802789, -0.1038921 ],\n",
       "       [-0.11157634,  1.95462113],\n",
       "       [-0.70576986, -0.33583725],\n",
       "       [-0.50770535, -0.8287207 ],\n",
       "       [ 0.68068169, -1.37959044],\n",
       "       [-0.80480212, -1.58254245],\n",
       "       [-1.89415691, -1.46656987],\n",
       "       [ 1.07681071,  0.12805305],\n",
       "       [ 0.08648817,  1.51972397],\n",
       "       [-0.30964085,  0.09905991],\n",
       "       [ 0.08648817,  0.04107362],\n",
       "       [-1.39899564, -1.3505973 ],\n",
       "       [ 0.28455268,  0.07006676],\n",
       "       [-0.90383437,  0.38899135],\n",
       "       [ 1.57197197, -1.26361786],\n",
       "       [-0.30964085, -0.74174127],\n",
       "       [-0.11157634,  0.1570462 ],\n",
       "       [-0.90383437, -0.65476184],\n",
       "       [-0.70576986, -0.04590581],\n",
       "       [ 0.38358493, -0.45180983],\n",
       "       [-0.80480212,  1.89663484],\n",
       "       [ 1.37390747,  1.28777882],\n",
       "       [ 1.17584296, -0.97368642],\n",
       "       [ 1.77003648,  1.83864855],\n",
       "       [-0.90383437, -0.24885782],\n",
       "       [-0.80480212,  0.56295021],\n",
       "       [-1.20093113, -1.5535493 ],\n",
       "       [-0.50770535, -1.11865214],\n",
       "       [ 0.28455268,  0.07006676],\n",
       "       [-0.21060859, -1.06066585],\n",
       "       [ 1.67100423,  1.6067034 ],\n",
       "       [ 0.97777845,  1.78066227],\n",
       "       [ 0.28455268,  0.04107362],\n",
       "       [-0.80480212, -0.21986468],\n",
       "       [-0.11157634,  0.07006676],\n",
       "       [ 0.28455268, -0.19087153],\n",
       "       [ 1.96810099, -0.65476184],\n",
       "       [-0.80480212,  1.3457651 ],\n",
       "       [-1.79512465, -0.59677555],\n",
       "       [-0.11157634,  0.12805305],\n",
       "       [ 0.28455268, -0.30684411],\n",
       "       [ 1.07681071,  0.56295021],\n",
       "       [-1.00286662,  0.27301877],\n",
       "       [ 1.47293972,  0.35999821],\n",
       "       [ 0.18552042, -0.3648304 ],\n",
       "       [ 2.1661655 , -1.03167271],\n",
       "       [-0.30964085,  1.11381995],\n",
       "       [-1.6960924 ,  0.07006676],\n",
       "       [-0.01254409,  0.04107362],\n",
       "       [ 0.08648817,  1.05583366],\n",
       "       [-0.11157634, -0.3648304 ],\n",
       "       [-1.20093113,  0.07006676],\n",
       "       [-0.30964085, -1.3505973 ],\n",
       "       [ 1.57197197,  1.11381995],\n",
       "       [-0.80480212, -1.52455616],\n",
       "       [ 0.08648817,  1.8676417 ],\n",
       "       [-0.90383437, -0.77073441],\n",
       "       [-0.50770535, -0.77073441],\n",
       "       [-0.30964085, -0.91570013],\n",
       "       [ 0.28455268, -0.71274813],\n",
       "       [ 0.28455268,  0.07006676],\n",
       "       [ 0.08648817,  1.8676417 ],\n",
       "       [-1.10189888,  1.95462113],\n",
       "       [-1.6960924 , -1.5535493 ],\n",
       "       [-1.20093113, -1.089659  ],\n",
       "       [-0.70576986, -0.1038921 ],\n",
       "       [ 0.08648817,  0.09905991],\n",
       "       [ 0.28455268,  0.27301877],\n",
       "       [ 0.8787462 , -0.5677824 ],\n",
       "       [ 0.28455268, -1.14764529],\n",
       "       [-0.11157634,  0.67892279],\n",
       "       [ 2.1661655 , -0.68375498],\n",
       "       [-1.29996338, -1.37959044],\n",
       "       [-1.00286662, -0.94469328],\n",
       "       [-0.01254409, -0.42281668],\n",
       "       [-0.21060859, -0.45180983],\n",
       "       [-1.79512465, -0.97368642],\n",
       "       [ 1.77003648,  0.99784738],\n",
       "       [ 0.18552042, -0.3648304 ],\n",
       "       [ 0.38358493,  1.11381995],\n",
       "       [-1.79512465, -1.3505973 ],\n",
       "       [ 0.18552042, -0.13288524],\n",
       "       [ 0.8787462 , -1.43757673],\n",
       "       [-1.99318916,  0.47597078],\n",
       "       [-0.30964085,  0.27301877],\n",
       "       [ 1.86906873, -1.06066585],\n",
       "       [-0.4086731 ,  0.07006676],\n",
       "       [ 1.07681071, -0.88670699],\n",
       "       [-1.10189888, -1.11865214],\n",
       "       [-1.89415691,  0.01208048],\n",
       "       [ 0.08648817,  0.27301877],\n",
       "       [-1.20093113,  0.33100506],\n",
       "       [-1.29996338,  0.30201192],\n",
       "       [-1.00286662,  0.44697764],\n",
       "       [ 1.67100423, -0.88670699],\n",
       "       [ 1.17584296,  0.53395707],\n",
       "       [ 1.07681071,  0.53395707],\n",
       "       [ 1.37390747,  2.331532  ],\n",
       "       [-0.30964085, -0.13288524],\n",
       "       [ 0.38358493, -0.45180983],\n",
       "       [-0.4086731 , -0.77073441],\n",
       "       [-0.11157634, -0.50979612],\n",
       "       [ 0.97777845, -1.14764529],\n",
       "       [-0.90383437, -0.77073441],\n",
       "       [-0.21060859, -0.50979612],\n",
       "       [-1.10189888, -0.45180983],\n",
       "       [-1.20093113,  1.40375139]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid activation\n",
    "\n",
    "In order to map predicted values to probabilities, we use the sigmoid function. The function maps any real value into another value between 0 and 1. In machine learning, we use sigmoid to map predictions to probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    #print(z)\n",
    "    return 1.0 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions\n",
    "\n",
    "Let’s use the same multiple linear regression equation:\n",
    "\n",
    "$$z = W_0 + W_1 * Age + W_2 * EstimatedSalary $$\n",
    "\n",
    "After that we will transform the output using the sigmoid function to return a probability value between 0 and 1.\n",
    "\n",
    "$$P(class=1) = \\frac{1}{1 + e^{-z}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(features,weights):\n",
    "    '''\n",
    "    Returns 1D array of probabilities\n",
    "    that the class label == 1\n",
    "    '''\n",
    "    #print(features.shape)\n",
    "    #print(\"weights: \", weights)\n",
    "    z=np.dot(features,weights)\n",
    "    #print(z)\n",
    "    return sigmoid(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function\n",
    "\n",
    "we use a cost function called Cross-Entropy, also known as Log Loss. Cross-entropy loss can be divided into two separate cost functions: one for y=1 and one for y=0.\n",
    "\n",
    "$$ J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^m [y^{(i)}log(h_{\\theta}(x^{(i)})) + (1-y^{(i)})log(1-h_{\\theta}(x^{(i)}))]$$\n",
    "\n",
    "The benefits of taking the logarithm reveal themselves when you look at the cost function graphs for y=1 and y=0. These smooth monotonic functions (always increasing or always decreasing) make it easy to calculate the gradient and minimize cost. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(features,labels,weights):\n",
    "    \n",
    "    observations = len(labels)\n",
    "    \n",
    "    predictions=predict(features,weights)\n",
    "    \n",
    "    #Take the error when label=1\n",
    "    class1_cost = -labels*np.log(predictions)\n",
    "\n",
    "    #Take the error when label=0\n",
    "    class2_cost = (1-labels)*np.log(1-predictions)\n",
    "\n",
    "    #Take the sum of both costs\n",
    "    cost = class1_cost - class2_cost\n",
    "\n",
    "    #Take the average cost\n",
    "    cost = cost.sum() / observations\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent\n",
    "\n",
    "To minimize our cost, we use Gradient Descent.\n",
    "\n",
    "The derivative of the sigmoid function:\n",
    "$$s'(z)=s(z)(1−s(z))$$\n",
    "\n",
    "Which leads to an equally beautiful and convenient cost function derivative:\n",
    "$$C′=x(s(z)−y)$$\n",
    "\n",
    "C′  is the derivative of cost with respect to weights\\\\\n",
    "\n",
    "y is the actual class label (0 or 1)\\\\\n",
    "\n",
    "s(z)  is your model’s prediction\\\\\n",
    "\n",
    "x  is your feature or feature vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step is assign class labels (0 or 1) to our predicted probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_boundary(prob):\n",
    "    return 1 if prob >= .5 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert probabilities to classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(predictions):\n",
    "    '''\n",
    "    input  - N element array of predictions between 0 and 1\n",
    "    output - N element array of 0s (False) and 1s (True)\n",
    "    '''\n",
    "    decision_boundary_res = decision_boundary(predictions)\n",
    "    decision_boundary_res = np.vectorize(decision_boundary_res)\n",
    "    return decision_boundary_res.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(features, labels, weights, lr):\n",
    "    '''\n",
    "    Vectorized Gradient Descent\n",
    "\n",
    "    Features:(200, 3)\n",
    "    Labels: (200, 1)\n",
    "    Weights:(3, 1)\n",
    "    '''\n",
    "    N = len(features)\n",
    "    #print(\"features=\",features.shape)\n",
    "    #print(\"labels=\",labels.shape)\n",
    "    #print(\"weights=\",weights.shape)\n",
    "    #1 - Get Predictions\n",
    "    predictions = predict(features, weights)\n",
    "    #print(predictions)\n",
    "    #predictions = classify(predictions)\n",
    "    #predictions = np.amax(predictions, axis=1)\n",
    "    #2 Transpose features from (200, 3) to (3, 200)\n",
    "    # So we can multiply w the (200,1)  cost matrix.\n",
    "    # Returns a (3,1) matrix holding 3 partial derivatives --\n",
    "    # one for each feature -- representing the aggregate\n",
    "    # slope of the cost function across all observations\n",
    "    #print(features.T)\n",
    "    #print(\"predictions: \", predictions)\n",
    "    #print(\"\\n\")\n",
    "    #print(labels)\n",
    "    gradient = np.dot(features.T,  predictions - labels)\n",
    "\n",
    "    #3 Take the average cost derivative for each feature\n",
    "    gradient /= N\n",
    "\n",
    "    #4 - Multiply the gradient by our learning rate\n",
    "    gradient *= lr\n",
    "\n",
    "    #5 - Subtract from our weights to minimize cost\n",
    "    weights -= gradient\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(features, labels, weights, lr, iters):\n",
    "    cost_history = []\n",
    "\n",
    "    for i in range(iters):\n",
    "        weights = update_weights(features, labels, weights, lr)\n",
    "        #print(\"weights: \", weights)\n",
    "        #print(\"features: \", features)\n",
    "        #Calculate error for auditing purposes\n",
    "        cost = cost_function(features, labels, weights)\n",
    "        cost_history.append(cost)\n",
    "\n",
    "        # Log Progress\n",
    "        if i % 1000 == 0:\n",
    "            print (\"iter: \"+str(i) + \" cost: \"+str(cost))\n",
    "\n",
    "    return weights, cost_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predicted_labels, actual_labels):\n",
    "    diff = predicted_labels - actual_labels\n",
    "    return 1.0 - (float(np.count_nonzero(diff)) / len(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(trues, falses):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    no_of_preds = len(trues) + len(falses)\n",
    "\n",
    "    ax.scatter([i for i in range(len(trues))], trues, s=25, c='b', marker=\"o\", label='Trues')\n",
    "    ax.scatter([i for i in range(len(falses))], falses, s=25, c='r', marker=\"s\", label='Falses')\n",
    "\n",
    "    plt.legend(loc='upper right');\n",
    "    ax.set_title(\"Decision Boundary\")\n",
    "    ax.set_xlabel('N/2')\n",
    "    ax.set_ylabel('Predicted Probability')\n",
    "    plt.axhline(.5, color='black')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0 cost: 0.45909900051475516\n"
     ]
    }
   ],
   "source": [
    "weights, cost_history = train(A_train, b_train, (1,1), 1, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter([i for i in range(500)], cost_history, s=25, c='b', marker=\"o\", label='Trues')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
